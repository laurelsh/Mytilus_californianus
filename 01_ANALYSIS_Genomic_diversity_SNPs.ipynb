{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f79b7-73b7-415f-a525-d454a2e3b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 01_ANALYSIS: Genomic data processing and SNP identification\n",
    "######################################################################\n",
    "\n",
    "### Note that any block starting with \"SCRIPT\" or \"ON COMMAND LINE\" should be run in terminal and not in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706c313-01a3-475a-904d-5b38c333a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 1: SCRIPT: Trimming\n",
    "######################################################################\n",
    "\n",
    "conda activate trim-galore\n",
    "\n",
    "TRIM_GALORE_DIR=/home/local/ADS/lsh/anaconda3/envs/trim-galore/bin\n",
    "TRIM_DIR=/home/local/ADS/lsh/Mytilus-WGS/trimmed\n",
    "\n",
    "DIRS=(\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc9a\"\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc11a\"\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc14a\"\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc15a\"\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc18a\"\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc19a\"\n",
    "  \"/home/local/ADS/lsh/Yi_Lab/Lab_Archives/Raw_Seq_Data/20240501_Psomagen_mussel_pilot/mc24a\"\n",
    ")\n",
    "\n",
    "trim_command=\"\"\n",
    "for dir in \"${DIRS[@]}\"; do\n",
    "  s=$(basename \"$dir\")\n",
    "  trim_command=\"$trim_command --paired ${dir}/${s}_1.fastq.gz ${dir}/${s}_2.fastq.gz\"\n",
    "done\n",
    "\n",
    "$TRIM_GALORE_DIR/trim_galore --path_to_cutadapt /home/local/ADS/lsh/anaconda3/envs/trim-galore/bin/cutadapt \\\n",
    "  --output_dir $TRIM_DIR $trim_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9e3c9-9576-4549-8985-2185d476b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 2: SCRIPT: Bowtie2 mapping, mark-dup, index (array SLURM)\n",
    "######################################################################\n",
    "## (SLURM SCRIPT: wgs_bowtie2_map.slurm)\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --job-name=wgs_map_bt2\n",
    "#SBATCH --partition=debug\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --time=1-00:00:00\n",
    "#SBATCH --output=logs/wgs_bt2.%A_%a.out\n",
    "#SBATCH --error=logs/wgs_bt2.%A_%a.err\n",
    "\n",
    "set -euo pipefail\n",
    "BISM=\"/home/local/ADS/lsh/anaconda3/envs/bismark/bin\"\n",
    "BOWTIE2=\"$BISM/bowtie2\"\n",
    "SAMTOOLS=\"$BISM/samtools\"\n",
    "\n",
    "SAMPLES_FILE=\"$HOME/Mytilus/m-samples.txt\"\n",
    "BT2_PREFIX=\"$HOME/Mytilus/genome/bt2/mytilus_californianus_genome\"\n",
    "MAPDIR=\"$HOME/Mytilus-WGS/mapping_bt2\"\n",
    "mkdir -p \"$MAPDIR\" \"$MAPDIR/tmp\"\n",
    "\n",
    "if [[ -z \"${SAMPLE:-}\" ]]; then\n",
    "  : \"${SLURM_ARRAY_TASK_ID:?Array index required or set SAMPLE=...}\"\n",
    "  SAMPLE=\"$(sed -n \"${SLURM_ARRAY_TASK_ID}p\" \"$SAMPLES_FILE\")\"\n",
    "fi\n",
    "\n",
    "R1=\"$HOME/Mytilus-WGS/trimmed/${SAMPLE}_1_val_1.fq.gz\"\n",
    "R2=\"$HOME/Mytilus-WGS/trimmed/${SAMPLE}_2_val_2.fq.gz\"\n",
    "\n",
    "for f in 1 2 3 4 rev.1 rev.2; do\n",
    "  while [[ ! -s \"${BT2_PREFIX}.${f}.bt2\" ]]; do sleep 5; done\n",
    "done\n",
    "\n",
    "TMPPFX=\"$MAPDIR/tmp_${SAMPLE}\"\n",
    "LOG=\"$MAPDIR/${SAMPLE}.bt2.log\"\n",
    "\n",
    "$BOWTIE2 -x \"$BT2_PREFIX\" -1 \"$R1\" -2 \"$R2\" -p \"${SLURM_CPUS_PER_TASK}\" 2> \"$LOG\" \\\n",
    "| $SAMTOOLS view -b -@ \"${SLURM_CPUS_PER_TASK}\" \\\n",
    "| $SAMTOOLS sort -n -@ \"${SLURM_CPUS_PER_TASK}\" -m 2G -T \"${TMPPFX}/nsort\" -o \"$MAPDIR/${SAMPLE}.namesorted.bam\"\n",
    "\n",
    "$SAMTOOLS fixmate -@ \"${SLURM_CPUS_PER_TASK}\" -m \"$MAPDIR/${SAMPLE}.namesorted.bam\" \"$MAPDIR/${SAMPLE}.fixmate.bam\"\n",
    "$SAMTOOLS sort    -@ \"${SLURM_CPUS_PER_TASK}\" -o \"$MAPDIR/${SAMPLE}.coordsorted.bam\" \"$MAPDIR/${SAMPLE}.fixmate.bam\"\n",
    "$SAMTOOLS markdup -@ \"${SLURM_CPUS_PER_TASK}\" -r \"$MAPDIR/${SAMPLE}.coordsorted.bam\" \"$MAPDIR/${SAMPLE}.mkdup.bam\"\n",
    "$SAMTOOLS index   -@ \"${SLURM_CPUS_PER_TASK}\" \"$MAPDIR/${SAMPLE}.mkdup.bam\"\n",
    "$SAMTOOLS flagstat -@ \"${SLURM_CPUS_PER_TASK}\" \"$MAPDIR/${SAMPLE}.mkdup.bam\" > \"$MAPDIR/${SAMPLE}.flagstat.txt\"\n",
    "\n",
    "rm -f \"$MAPDIR/${SAMPLE}.namesorted.bam\" \"$MAPDIR/${SAMPLE}.fixmate.bam\" \"$MAPDIR/${SAMPLE}.coordsorted.bam\"\n",
    "echo \"Done: $MAPDIR/${SAMPLE}.mkdup.bam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3494d-225c-43e0-84e5-108d458d964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 3: IN TERMINAL: Average coverage and Coverage per-base\n",
    "######################################################################\n",
    "\n",
    "conda activate wgs-coverage-env\n",
    "cd ~/Mytilus-WGS\n",
    "mkdir -p wgs_coverage_bt2\n",
    "\n",
    "mapfile -t BAMS < <(ls -1 mapping_bt2/*.mkdup.bam)\n",
    "for b in \"${BAMS[@]}\"; do\n",
    "  s=$(basename \"$b\" .mkdup.bam)\n",
    "  echo \"==> mosdepth (per-base) $s\"\n",
    "  # NOTE: **NO -n** so that *.per-base.bed.gz is produced\n",
    "  mosdepth --fast-mode --threads 8 \"wgs_coverage_bt2/${s}\" \"$b\"\n",
    "done\n",
    "\n",
    "echo -e \"Sample\\tMeanDepth\"\n",
    "for f in wgs_coverage_bt2/*.mosdepth.summary.txt; do\n",
    "  s=$(basename \"$f\" .mosdepth.summary.txt)\n",
    "  awk -v s=\"$s\" 'NR==2 {print s \"\\t\" $4}' \"$f\"\n",
    "done\n",
    "\n",
    "# Sanity: ensure the per-base files now exist\n",
    "ls -1 wgs_coverage_bt2/*.per-base.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fa39b-882a-4f7a-9278-5753b068cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 4A: SCRIPT: SNP calling\n",
    "## This calls variants (bcftools) from the new mapping_bt2/*.mkdup.bam, indexes missing .bai, and emits both stringent (for π/θ/Ne) and relaxed VCFs.\n",
    "######################################################################\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --job-name=bcf_call_bt2\n",
    "#SBATCH --partition=debug\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=/home/local/ADS/lsh/Mytilus-WGS/logs/bcf_call_bt2.%j.out\n",
    "#SBATCH --error=/home/local/ADS/lsh/Mytilus-WGS/logs/bcf_call_bt2.%j.err\n",
    "\n",
    "set -euo pipefail\n",
    "\n",
    "# ========= paths =========\n",
    "WD=/home/local/ADS/lsh/Mytilus-WGS\n",
    "REF=/home/local/ADS/lsh/Mytilus/prepped_genome/mytilus_californianus_genome.fasta\n",
    "BAMDIR=\"$WD/mapping_bt2\"\n",
    "OUTDIR=\"$WD/snps\"\n",
    "LOGDIR=\"$WD/logs\"\n",
    "mkdir -p \"$OUTDIR\" \"$LOGDIR\"\n",
    "\n",
    "# ========= env =========\n",
    "# bcftools-env should contain bcftools, samtools, tabix (+fill-tags plugin)\n",
    "source ~/.bashrc\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate bcftools-env\n",
    "\n",
    "# ========= inputs =========\n",
    "# collect all mkdup BAMs\n",
    "mapfile -t BAMS < <(ls -1 \"${BAMDIR}\"/*.mkdup.bam)\n",
    "echo \"[INFO] Found ${#BAMS[@]} BAMs:\"\n",
    "printf '  %s\\n' \"${BAMS[@]}\"\n",
    "\n",
    "# sanity: reference + indexes\n",
    "[[ -s \"$REF\" ]] || { echo \"[ERR] Missing reference: $REF\" ; exit 1; }\n",
    "[[ -s \"${REF}.fai\" ]] || samtools faidx \"$REF\"\n",
    "\n",
    "# ========= outputs =========\n",
    "RAW_VCF=\"$OUTDIR/bcftools.snps.raw.vcf.gz\"\n",
    "RAW_TBI=\"${RAW_VCF}.tbi\"\n",
    "PG_TMP=\"$OUTDIR/_pg.tmp.vcf.gz\"\n",
    "PG_TMP_TBI=\"${PG_TMP}.tbi\"\n",
    "PG_TAG=\"$OUTDIR/bcftools.popgen.tags.vcf.gz\"\n",
    "PG_TAG_TBI=\"${PG_TAG}.tbi\"\n",
    "PG_STRICT=\"$OUTDIR/bcftools.popgen.strict.vcf.gz\"\n",
    "PG_STRICT_TBI=\"${PG_STRICT}.tbi\"\n",
    "\n",
    "echo \"[INFO] Writing:\"\n",
    "echo \"  RAW:     $RAW_VCF\"\n",
    "echo \"  TAGGED:  $PG_TAG\"\n",
    "echo \"  STRICT:  $PG_STRICT\"\n",
    "\n",
    "# ========= run =========\n",
    "echo \"[INFO] mpileup -> call (SNPs only, multiallelic OK; no indels)\"\n",
    "bcftools mpileup \\\n",
    "  --threads ${SLURM_CPUS_PER_TASK} \\\n",
    "  --skip-indels \\\n",
    "  -d 10000 \\\n",
    "  -f \"$REF\" \\\n",
    "  \"${BAMS[@]}\" -Ou \\\n",
    "| bcftools call \\\n",
    "    --threads ${SLURM_CPUS_PER_TASK} \\\n",
    "    --skip-variants indels \\\n",
    "    --multiallelic-caller \\\n",
    "    --variants-only \\\n",
    "    -Oz -o \"$RAW_VCF\"\n",
    "\n",
    "tabix -p vcf \"$RAW_VCF\"\n",
    "\n",
    "# biallelic-only intermediate for tagging (keeps PASS later)\n",
    "echo \"[INFO] make biallelic-only temp (SNPs, PASS later)\"\n",
    "bcftools view -f PASS -v snps -m2 -M2 -Oz -o \"$PG_TMP\" \"$RAW_VCF\"\n",
    "tabix -p vcf \"$PG_TMP\"\n",
    "\n",
    "# fill tags (MAF, F_MISSING, etc.)\n",
    "echo \"[INFO] +fill-tags (MAF, F_MISSING, AC, AN, NS)\"\n",
    "bcftools +fill-tags \"$PG_TMP\" -- -t MAF,F_MISSING,AC,AN,NS -Oz -o \"$PG_TAG\"\n",
    "tabix -p vcf \"$PG_TAG\"\n",
    "\n",
    "# strict pop-gen set: MAF>=0.05 and <=20% missing\n",
    "echo \"[INFO] strict filter (MAF>=0.05 && F_MISSING<=0.20)\"\n",
    "bcftools view -i 'MAF>=0.05 && F_MISSING<=0.20' \"$PG_TAG\" -Oz -o \"$PG_STRICT\"\n",
    "tabix -p vcf \"$PG_STRICT\"\n",
    "\n",
    "# cleanup temp\n",
    "rm -f \"$PG_TMP\" \"$PG_TMP_TBI\"\n",
    "\n",
    "echo \"[DONE] $(date)\"\n",
    "echo \"[OUT] RAW     : $RAW_VCF\"\n",
    "echo \"[OUT] STRICT  : $PG_STRICT\"\n",
    "\n",
    "# quick stats (handy)\n",
    "bcftools stats \"$RAW_VCF\" > \"$OUTDIR/bcftools.snps.raw.stats.txt\" || true\n",
    "bcftools stats \"$PG_STRICT\" > \"$OUTDIR/bcftools.popgen.strict.stats.txt\" || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c9558-5d02-443c-887e-c0ffc22ff112",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 4B: SCRIPT: SNP calling with FreeBayes\n",
    "######################################################################\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --job-name=freebayes_bt2\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=16G\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=logs/freebayes_%A_%a.out\n",
    "#SBATCH --error=logs/freebayes_%A_%a.err\n",
    "#SBATCH --array=0-6    # will reset just below\n",
    "\n",
    "set -euo pipefail\n",
    "\n",
    "# *** critical: conda hook so \"conda activate\" works in batch ***\n",
    "source ~/.bashrc\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate freebayes\n",
    "\n",
    "REF=\"/home/local/ADS/lsh/Mytilus/prepped_genome/mytilus_californianus_genome.fasta\"\n",
    "cd ~/Mytilus-WGS/mapping_bt2\n",
    "\n",
    "mapfile -t BAMS < <(ls -1 *.mkdup.bam)\n",
    "BAM=\"${BAMS[$SLURM_ARRAY_TASK_ID]}\"\n",
    "SAMPLE=\"${BAM%%.mkdup.bam}\"\n",
    "\n",
    "[[ -s \"${REF}.fai\" ]] || samtools faidx \"$REF\"\n",
    "[[ -s \"${BAM}.bai\" ]] || samtools index \"$BAM\"\n",
    "\n",
    "freebayes -f \"$REF\" \"$BAM\" > \"${SAMPLE}.raw.vcf\" 2> \"${SAMPLE}.freebayes.log\"\n",
    "grep -m1 '^##source=free' \"${SAMPLE}.raw.vcf\" >/dev/null\n",
    "bgzip -@ \"${SLURM_CPUS_PER_TASK}\" -f \"${SAMPLE}.raw.vcf\"\n",
    "tabix -p vcf \"${SAMPLE}.raw.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f59c37-003f-4f7c-9b18-625e049315c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 5. SCRIPT: Merge SNP calls FreeBayes\n",
    "######################################################################\n",
    "\n",
    "conda activate freebayes\n",
    "cd ~/Mytilus-WGS/mapping_bt2\n",
    "bcftools merge *.raw.vcf.gz -Oz -o cohort.raw.vcf.gz\n",
    "tabix -p vcf cohort.raw.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3a16e-2498-4a42-a0e9-0e0b503df08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 6: SCRIPT: SNP → BED (all SNPs) and CpG-only SNP BED, Make callable mask, Combine “callable” with SNP masks to get masked regions for diversity\n",
    "######################################################################\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --job-name=callable_masks\n",
    "#SBATCH --partition=debug\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=16G\n",
    "#SBATCH --time=06:00:00\n",
    "#SBATCH --output=logs/callable_masks.%j.out\n",
    "#SBATCH --error=logs/callable_masks.%j.err\n",
    "set -euo pipefail\n",
    "\n",
    "WD=\"$HOME/Mytilus-WGS\"\n",
    "COVDIR=\"$WD/wgs_coverage_bt2\"\n",
    "OUTDIR=\"$WD/snps\"\n",
    "mkdir -p \"$OUTDIR\" \"$WD/logs\"\n",
    "\n",
    "# tools (bedtools recommended; awk fallback will be used if not found)\n",
    "BEDTOOLS=$(command -v bedtools || true)\n",
    "\n",
    "# samples = inferred from per-base files\n",
    "mapfile -t SAMPLES < <(cd \"$COVDIR\" && ls -1 *.per-base.bed.gz | sed 's/\\.per-base\\.bed\\.gz$//')\n",
    "\n",
    "echo \"[INFO] Samples: ${SAMPLES[*]}\"\n",
    "\n",
    "# function: merge adjacent intervals with awk (fallback if bedtools missing)\n",
    "merge_awk='\n",
    "BEGIN{OFS=\"\\t\"}\n",
    "NR==1{c=$1;s=$2;e=$3;next}\n",
    "{\n",
    "  if($1==c && $2==e){ e=$3 }  # extend if adjacent\n",
    "  else { print c,s,e; c=$1; s=$2; e=$3 }\n",
    "}\n",
    "END{ if(NR>0) print c,s,e }\n",
    "'\n",
    "\n",
    "# 1) per-sample callable BEDs\n",
    "declare -a CALL_BEDS=()\n",
    "for s in \"${SAMPLES[@]}\"; do\n",
    "  sum=\"$COVDIR/${s}.mosdepth.summary.txt\"\n",
    "  pbase=\"$COVDIR/${s}.per-base.bed.gz\"\n",
    "  [[ -s \"$sum\" && -s \"$pbase\" ]] || { echo \"[ERR] Missing mosdepth outputs for $s\"; exit 1; }\n",
    "\n",
    "  mean=$(awk 'NR==2{print $4}' \"$sum\")\n",
    "  # thresholds: MIN=4, MAX=ceil(3*mean) capped at 60\n",
    "  MIN=4\n",
    "  MAX=$(python3 - <<PY\n",
    "import math\n",
    "m=float(\"$mean\")\n",
    "print(int(min(60, math.ceil(3*m))))\n",
    "PY\n",
    ")\n",
    "  echo \"[INFO] $s mean=$mean  MIN=$MIN  MAX=$MAX\"\n",
    "\n",
    "  out=\"$OUTDIR/${s}.callable.bed\"\n",
    "  # select segments with depth between MIN and MAX inclusive, then merge\n",
    "  if [[ -n \"$BEDTOOLS\" ]]; then\n",
    "    zcat \"$pbase\" \\\n",
    "      | awk -v mn=\"$MIN\" -v mx=\"$MAX\" 'BEGIN{OFS=\"\\t\"} ($4>=mn && $4<=mx){print $1,$2,$3}' \\\n",
    "      | \"$BEDTOOLS\" sort -i stdin \\\n",
    "      | \"$BEDTOOLS\" merge -i stdin \\\n",
    "      > \"$out\"\n",
    "  else\n",
    "    zcat \"$pbase\" \\\n",
    "      | awk -v mn=\"$MIN\" -v mx=\"$MAX\" 'BEGIN{OFS=\"\\t\"} ($4>=mn && $4<=mx){print $1,$2,$3}' \\\n",
    "      | sort -k1,1 -k2,2n -k3,3n \\\n",
    "      | awk \"$merge_awk\" \\\n",
    "      > \"$out\"\n",
    "  fi\n",
    "  [[ -s \"$out\" ]] || { echo \"[ERR] no callable intervals for $s\"; exit 1; }\n",
    "  CALL_BEDS+=(\"$out\")\n",
    "done\n",
    "\n",
    "# 2) cohort masks\n",
    "#    intersection (callable in ALL samples)\n",
    "COHORT_ALL=\"$OUTDIR/cohort_callable_all.bed\"\n",
    "#    union (callable in AT LEAST ONE sample)\n",
    "COHORT_ANY=\"$OUTDIR/cohort_callable_any.bed\"\n",
    "\n",
    "if [[ -n \"$BEDTOOLS\" ]]; then\n",
    "  # union\n",
    "  \"$BEDTOOLS\" sort -i <(cat \"${CALL_BEDS[@]}\") | \"$BEDTOOLS\" merge -i stdin > \"$COHORT_ANY\"\n",
    "  # intersection (iterate pairwise to avoid multiinter dependency)\n",
    "  cp \"${CALL_BEDS[0]}\" \"$COHORT_ALL.tmp\"\n",
    "  for ((i=1;i<${#CALL_BEDS[@]};i++)); do\n",
    "    \"$BEDTOOLS\" intersect -a \"$COHORT_ALL.tmp\" -b \"${CALL_BEDS[$i]}\" > \"$COHORT_ALL.tmp2\"\n",
    "    mv \"$COHORT_ALL.tmp2\" \"$COHORT_ALL.tmp\"\n",
    "  done\n",
    "  mv \"$COHORT_ALL.tmp\" \"$COHORT_ALL\"\n",
    "else\n",
    "  # union (awk fallback): concat -> sort -> merge\n",
    "  cat \"${CALL_BEDS[@]}\" \\\n",
    "    | sort -k1,1 -k2,2n -k3,3n \\\n",
    "    | awk \"$merge_awk\" > \"$COHORT_ANY\"\n",
    "\n",
    "  # intersection fallback: build coverage counts by collapsing starts/ends\n",
    "  # (simpler to require bedtools for intersection on big genomes)\n",
    "  echo \"[ERR] bedtools not found; cannot compute robust intersection without it.\"\n",
    "  echo \"      Please install bedtools or run the intersection later.\"\n",
    "  COHORT_ALL=\"/dev/null\"\n",
    "fi\n",
    "\n",
    "# 3) quick stats\n",
    "for b in \"${CALL_BEDS[@]}\"; do\n",
    "  bp=$(awk '{s+=$3-$2}END{print s+0}' \"$b\")\n",
    "  echo \"[STATS] $(basename \"$b\"): ${bp} bp\"\n",
    "done\n",
    "\n",
    "if [[ -s \"$COHORT_ANY\" ]]; then\n",
    "  bp_any=$(awk '{s+=$3-$2}END{print s+0}' \"$COHORT_ANY\")\n",
    "  echo \"[STATS] cohort_callable_any: ${bp_any} bp\"\n",
    "fi\n",
    "\n",
    "if [[ -s \"$COHORT_ALL\" && \"$COHORT_ALL\" != \"/dev/null\" ]]; then\n",
    "  bp_all=$(awk '{s+=$3-$2}END{print s+0}' \"$COHORT_ALL\")\n",
    "  echo \"[STATS] cohort_callable_all: ${bp_all} bp\"\n",
    "fi\n",
    "\n",
    "echo \"[DONE] Callable masks in $OUTDIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58be2ae-7a55-4389-a8f3-c5ea9f2e8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## 7: SCRIPT: Run genome-wide π, θ, Tajima’s D, Nₑ as a single SLURM job (SLURM SCRIPT: diversity_all.slurm)\n",
    "######################################################################\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --job-name=diversity_all\n",
    "#SBATCH --partition=debug\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=32G\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --output=logs/diversity_all.%j.out\n",
    "#SBATCH --error=logs/diversity_all.%j.err\n",
    "set -euo pipefail\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate bcftools-env\n",
    "\n",
    "WD=~/Mytilus-WGS\n",
    "REF=/home/local/ADS/lsh/Mytilus/prepped_genome/mytilus_californianus_genome.fasta\n",
    "VCF=${WD}/snps/bcftools.popgen.strict.vcf.gz\n",
    "MASK=${WD}/snps/callable_minus_snps.bed   # or callable_minus_cpg_snps.bed for methylation-aware\n",
    "OUTPFX=${WD}/snps/snps_filtered_bt2\n",
    "MU=8.6e-9\n",
    "\n",
    "[[ -f \"${REF}.fai\" ]] || samtools faidx \"$REF\"\n",
    "mkdir -p \"${WD}/snps\"\n",
    "\n",
    "# Filter to callable, PASS SNPs, biallelic\n",
    "bcftools view -R \"$MASK\" -f PASS -v snps -m2 -M2 -Oz -o \"${OUTPFX}.vcf.gz\" \"$VCF\"\n",
    "tabix -p vcf \"${OUTPFX}.vcf.gz\"\n",
    "\n",
    "# π (site + windowed)\n",
    "vcftools --gzvcf \"${OUTPFX}.vcf.gz\" --site-pi --out \"${OUTPFX}_site_pi\"\n",
    "vcftools --gzvcf \"${OUTPFX}.vcf.gz\" --window-pi 100000 --window-pi-step 100000 --out \"${OUTPFX}_windowed_pi\"\n",
    "\n",
    "# Tajima’s D (windowed + one large window ≈ genome-wide)\n",
    "vcftools --gzvcf \"${OUTPFX}.vcf.gz\" --TajimaD 100000 --out \"${OUTPFX}_windowed_TajimaD\" || true\n",
    "EFF_LEN=$(awk '{s+=$3-$2}END{print s}' \"$MASK\")\n",
    "vcftools --gzvcf \"${OUTPFX}.vcf.gz\" --TajimaD ${EFF_LEN} --out \"${OUTPFX}_tajimaD\" || true\n",
    "\n",
    "# θ_Watterson via allele freqs\n",
    "vcftools --gzvcf \"${OUTPFX}.vcf.gz\" --freq --out \"${OUTPFX}_freq\"\n",
    "\n",
    "# Summaries\n",
    "SUM_PI=$(awk 'NR>1{sum+=$3}END{printf(\"%.10f\", sum+0)}' \"${OUTPFX}_site_pi.sites.pi\")\n",
    "PI_GENOME=$(python3 - <<PY\n",
    "eff=${EFF_LEN}; s=float(\"${SUM_PI}\")\n",
    "print(f\"{s/eff:.10f}\")\n",
    "PY\n",
    ")\n",
    "\n",
    "SITES=$(grep -cv '^#' \"${OUTPFX}_freq.frq\")\n",
    "N_SAMPLES=$(bcftools query -l \"${OUTPFX}.vcf.gz\" | wc -l)\n",
    "N_CHR=$((2 * N_SAMPLES))\n",
    "A_N=$(python3 - <<PY\n",
    "n=${N_CHR}\n",
    "print(sum(1.0/i for i in range(1,n)) if n>1 else float('nan'))\n",
    "PY\n",
    ")\n",
    "THETA_RAW=$(python3 - <<PY\n",
    "sites=${SITES}; a=${A_N}\n",
    "print(f\"{(sites/a):.10f}\")\n",
    "PY\n",
    ")\n",
    "THETA_NORM=$(python3 - <<PY\n",
    "t=float(\"${THETA_RAW}\"); eff=${EFF_LEN}\n",
    "print(f\"{t/eff:.12f}\")\n",
    "PY\n",
    ")\n",
    "D_AVG=$(awk 'NR>1 && $4!=\".\"{sum+=$4;cnt++}END{if(cnt>0) printf(\"%.6f\", sum/cnt); else print \"NA\"}' \"${OUTPFX}_tajimaD.Tajima.D\" 2>/dev/null || echo \"NA\")\n",
    "NE=$(python3 - <<PY\n",
    "pi=float(\"${PI_GENOME}\"); mu=${MU}\n",
    "print(f\"{pi/(4*mu):.2f}\")\n",
    "PY\n",
    ")\n",
    "\n",
    "SUMMARY=\"${WD}/genomewide_diversity_summary.tsv\"\n",
    "if [[ ! -s \"$SUMMARY\" ]]; then\n",
    "  echo -e \"PREFIX\\tN_SAMPLES\\tSITES\\tPI_genomewide\\tTHETA_W_raw\\tTHETA_W_norm\\tTAJIMA_D_avg\\tNE(mu=${MU})\\tLEN_USED\" > \"$SUMMARY\"\n",
    "fi\n",
    "echo -e \"$(basename \"${OUTPFX}\")\\t${N_SAMPLES}\\t${SITES}\\t${PI_GENOME}\\t${THETA_RAW}\\t${THETA_NORM}\\t${D_AVG}\\t${NE}\\t${EFF_LEN}\" >> \"$SUMMARY\"\n",
    "column -t \"$SUMMARY\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:r]",
   "language": "R",
   "name": "conda-env-r-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
